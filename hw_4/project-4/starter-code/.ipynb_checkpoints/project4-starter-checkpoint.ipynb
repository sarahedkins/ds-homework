{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4\n",
    "\n",
    "In this project, you will summarize and present your analysis from Projects 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro: Write a problem Statement/ Specific Aim for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  The aim for this project is to determine if we can make reasonable predictions of grad school admissions based on GRE, GPA and schook rank data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:  Write up a description of your data and any cleaning that was completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "The data included observations of GRE scores, GPA, and school rank, and whether or not the student was admitted to the grad school. \n",
    "\n",
    "We dropped observations (rows) with data NA in columns. \n",
    "We transformed categorical data of school rank into dummy variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Demo: Provide a table that explains the data by admission status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean (STD) or counts by admission status for each variable \n",
    "\n",
    "| Not Admitted | Admitted\n",
    "---| ---|---\n",
    "GPA | mean(std)  | mean(std)\n",
    "GRE |mean(std) | mean(std)\n",
    "Prestige 1 | frequency (%) | frequency (%)\n",
    "Prestige 2 | frequency (%) | frequency (%)\n",
    "Prestige 3 |frequency (%) | frequency (%)\n",
    "Prestige 4 |frequency (%) | frequency (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618.571428571\n",
      "573.579335793\n"
     ]
    }
   ],
   "source": [
    "mean_gre_admitted = df[(df['admit'] != 0)]['gre'].mean()\n",
    "print mean_gre_admitted\n",
    "\n",
    "mean_gre_not_admitted = df[(df['admit'] != 1)]['gre'].mean()\n",
    "print mean_gre_not_admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.48920634921\n",
      "3.34715867159\n"
     ]
    }
   ],
   "source": [
    "mean_gpa_admitted = df[df['admit'] != 0]['gpa'].mean()\n",
    "print mean_gpa_admitted\n",
    "\n",
    "mean_gpa_not_admitted = df[df['admit'] != 1]['gpa'].mean()\n",
    "print mean_gpa_not_admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    148\n",
       "3.0    121\n",
       "4.0     67\n",
       "1.0     61\n",
       "Name: prestige, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prestige'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods: Write up the methods used in your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Write up your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visuals: Provide a table or visualization of these results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='placeholder.png' height= 25% width= 25%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='placeholder.png' height= 25% width= 25%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Write up your discussion and future steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
